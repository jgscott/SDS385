

# Exercises

## Preliminaries

The goal of this warm-up assignment is to provide you with an introduction to optimization and its role in data analysis.  

For this section, please read Chapter 2 of _Numerical Optimization_, by Nocedal and Wright.  The full text of this book is available for free through the [UT Library website](http://lib.utexas.edu).  You should come away with a good general understanding of two methods for optimizing smooth functions:  
1) the method of steepest descent, or simply _gradient descent_, and   
2) Newton's method.  

Feel free to skip the stuff about trust-region methods.  The overview of quasi-Newton methods is nice, but optional for now.  

The [exercises for this unit](exercises01/exercises01-SDS385.pdf) will have you practice these techniques.  They will also will hammer your linear algebra skills.  
